{"ast":null,"code":"\"use strict\";\n\nexports.__esModule = true;\n\nvar _isEmpty = require(\"lodash/isEmpty\");\n\nvar _isEmpty2 = _interopRequireDefault(_isEmpty);\n\nvar _escapeRegExp = require(\"lodash/escapeRegExp\");\n\nvar _escapeRegExp2 = _interopRequireDefault(_escapeRegExp);\n\nvar _tokenTypes = require(\"./tokenTypes\");\n\nvar _tokenTypes2 = _interopRequireDefault(_tokenTypes);\n\nfunction _interopRequireDefault(obj) {\n  return obj && obj.__esModule ? obj : {\n    \"default\": obj\n  };\n}\n\nfunction _classCallCheck(instance, Constructor) {\n  if (!(instance instanceof Constructor)) {\n    throw new TypeError(\"Cannot call a class as a function\");\n  }\n}\n\nvar Tokenizer = function () {\n  /**\n   * @param {Object} cfg\n   *  @param {String[]} cfg.reservedWords Reserved words in SQL\n   *  @param {String[]} cfg.reservedToplevelWords Words that are set to new line separately\n   *  @param {String[]} cfg.reservedNewlineWords Words that are set to newline\n   *  @param {String[]} cfg.stringTypes String types to enable: \"\", '', ``, [], N''\n   *  @param {String[]} cfg.openParens Opening parentheses to enable, like (, [\n   *  @param {String[]} cfg.closeParens Closing parentheses to enable, like ), ]\n   *  @param {String[]} cfg.indexedPlaceholderTypes Prefixes for indexed placeholders, like ?\n   *  @param {String[]} cfg.namedPlaceholderTypes Prefixes for named placeholders, like @ and :\n   *  @param {String[]} cfg.lineCommentTypes Line comments to enable, like # and --\n   *  @param {String[]} cfg.specialWordChars Special chars that can be found inside of words, like @ and #\n   */\n  function Tokenizer(cfg) {\n    _classCallCheck(this, Tokenizer);\n\n    this.WHITESPACE_REGEX = /^(\\s+)/;\n    this.NUMBER_REGEX = /^((-\\s*)?[0-9]+(\\.[0-9]+)?|0x[0-9a-fA-F]+|0b[01]+)\\b/;\n    this.OPERATOR_REGEX = /^(!=|<>|==|<=|>=|!<|!>|\\|\\||::|->>|->|~~\\*|~~|!~~\\*|!~~|~\\*|!~\\*|!~|.)/;\n    this.BLOCK_COMMENT_REGEX = /^(\\/\\*[^]*?(?:\\*\\/|$))/;\n    this.LINE_COMMENT_REGEX = this.createLineCommentRegex(cfg.lineCommentTypes);\n    this.RESERVED_TOPLEVEL_REGEX = this.createReservedWordRegex(cfg.reservedToplevelWords);\n    this.RESERVED_NEWLINE_REGEX = this.createReservedWordRegex(cfg.reservedNewlineWords);\n    this.RESERVED_PLAIN_REGEX = this.createReservedWordRegex(cfg.reservedWords);\n    this.WORD_REGEX = this.createWordRegex(cfg.specialWordChars);\n    this.STRING_REGEX = this.createStringRegex(cfg.stringTypes);\n    this.OPEN_PAREN_REGEX = this.createParenRegex(cfg.openParens);\n    this.CLOSE_PAREN_REGEX = this.createParenRegex(cfg.closeParens);\n    this.INDEXED_PLACEHOLDER_REGEX = this.createPlaceholderRegex(cfg.indexedPlaceholderTypes, \"[0-9]*\");\n    this.IDENT_NAMED_PLACEHOLDER_REGEX = this.createPlaceholderRegex(cfg.namedPlaceholderTypes, \"[a-zA-Z0-9._$]+\");\n    this.STRING_NAMED_PLACEHOLDER_REGEX = this.createPlaceholderRegex(cfg.namedPlaceholderTypes, this.createStringPattern(cfg.stringTypes));\n  }\n\n  Tokenizer.prototype.createLineCommentRegex = function createLineCommentRegex(lineCommentTypes) {\n    return new RegExp(\"^((?:\" + lineCommentTypes.map(function (c) {\n      return (0, _escapeRegExp2[\"default\"])(c);\n    }).join(\"|\") + \").*?(?:\\n|$))\");\n  };\n\n  Tokenizer.prototype.createReservedWordRegex = function createReservedWordRegex(reservedWords) {\n    var reservedWordsPattern = reservedWords.join(\"|\").replace(/ /g, \"\\\\s+\");\n    return new RegExp(\"^(\" + reservedWordsPattern + \")\\\\b\", \"i\");\n  };\n\n  Tokenizer.prototype.createWordRegex = function createWordRegex() {\n    var specialChars = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : [];\n    return new RegExp(\"^([\\\\w\" + specialChars.join(\"\") + \"]+)\");\n  };\n\n  Tokenizer.prototype.createStringRegex = function createStringRegex(stringTypes) {\n    return new RegExp(\"^(\" + this.createStringPattern(stringTypes) + \")\");\n  }; // This enables the following string patterns:\n  // 1. backtick quoted string using `` to escape\n  // 2. square bracket quoted string (SQL Server) using ]] to escape\n  // 3. double quoted string using \"\" or \\\" to escape\n  // 4. single quoted string using '' or \\' to escape\n  // 5. national character quoted string using N'' or N\\' to escape\n\n\n  Tokenizer.prototype.createStringPattern = function createStringPattern(stringTypes) {\n    var patterns = {\n      \"``\": \"((`[^`]*($|`))+)\",\n      \"[]\": \"((\\\\[[^\\\\]]*($|\\\\]))(\\\\][^\\\\]]*($|\\\\]))*)\",\n      \"\\\"\\\"\": \"((\\\"[^\\\"\\\\\\\\]*(?:\\\\\\\\.[^\\\"\\\\\\\\]*)*(\\\"|$))+)\",\n      \"''\": \"(('[^'\\\\\\\\]*(?:\\\\\\\\.[^'\\\\\\\\]*)*('|$))+)\",\n      \"N''\": \"((N'[^N'\\\\\\\\]*(?:\\\\\\\\.[^N'\\\\\\\\]*)*('|$))+)\"\n    };\n    return stringTypes.map(function (t) {\n      return patterns[t];\n    }).join(\"|\");\n  };\n\n  Tokenizer.prototype.createParenRegex = function createParenRegex(parens) {\n    var _this = this;\n\n    return new RegExp(\"^(\" + parens.map(function (p) {\n      return _this.escapeParen(p);\n    }).join(\"|\") + \")\", \"i\");\n  };\n\n  Tokenizer.prototype.escapeParen = function escapeParen(paren) {\n    if (paren.length === 1) {\n      // A single punctuation character\n      return (0, _escapeRegExp2[\"default\"])(paren);\n    } else {\n      // longer word\n      return \"\\\\b\" + paren + \"\\\\b\";\n    }\n  };\n\n  Tokenizer.prototype.createPlaceholderRegex = function createPlaceholderRegex(types, pattern) {\n    if ((0, _isEmpty2[\"default\"])(types)) {\n      return false;\n    }\n\n    var typesRegex = types.map(_escapeRegExp2[\"default\"]).join(\"|\");\n    return new RegExp(\"^((?:\" + typesRegex + \")(?:\" + pattern + \"))\");\n  };\n  /**\n   * Takes a SQL string and breaks it into tokens.\n   * Each token is an object with type and value.\n   *\n   * @param {String} input The SQL string\n   * @return {Object[]} tokens An array of tokens.\n   *  @return {String} token.type\n   *  @return {String} token.value\n   */\n\n\n  Tokenizer.prototype.tokenize = function tokenize(input) {\n    var tokens = [];\n    var token = void 0; // Keep processing the string until it is empty\n\n    while (input.length) {\n      // Get the next token and the token type\n      token = this.getNextToken(input, token); // Advance the string\n\n      input = input.substring(token.value.length);\n      tokens.push(token);\n    }\n\n    return tokens;\n  };\n\n  Tokenizer.prototype.getNextToken = function getNextToken(input, previousToken) {\n    return this.getWhitespaceToken(input) || this.getCommentToken(input) || this.getStringToken(input) || this.getOpenParenToken(input) || this.getCloseParenToken(input) || this.getPlaceholderToken(input) || this.getNumberToken(input) || this.getReservedWordToken(input, previousToken) || this.getWordToken(input) || this.getOperatorToken(input);\n  };\n\n  Tokenizer.prototype.getWhitespaceToken = function getWhitespaceToken(input) {\n    return this.getTokenOnFirstMatch({\n      input: input,\n      type: _tokenTypes2[\"default\"].WHITESPACE,\n      regex: this.WHITESPACE_REGEX\n    });\n  };\n\n  Tokenizer.prototype.getCommentToken = function getCommentToken(input) {\n    return this.getLineCommentToken(input) || this.getBlockCommentToken(input);\n  };\n\n  Tokenizer.prototype.getLineCommentToken = function getLineCommentToken(input) {\n    return this.getTokenOnFirstMatch({\n      input: input,\n      type: _tokenTypes2[\"default\"].LINE_COMMENT,\n      regex: this.LINE_COMMENT_REGEX\n    });\n  };\n\n  Tokenizer.prototype.getBlockCommentToken = function getBlockCommentToken(input) {\n    return this.getTokenOnFirstMatch({\n      input: input,\n      type: _tokenTypes2[\"default\"].BLOCK_COMMENT,\n      regex: this.BLOCK_COMMENT_REGEX\n    });\n  };\n\n  Tokenizer.prototype.getStringToken = function getStringToken(input) {\n    return this.getTokenOnFirstMatch({\n      input: input,\n      type: _tokenTypes2[\"default\"].STRING,\n      regex: this.STRING_REGEX\n    });\n  };\n\n  Tokenizer.prototype.getOpenParenToken = function getOpenParenToken(input) {\n    return this.getTokenOnFirstMatch({\n      input: input,\n      type: _tokenTypes2[\"default\"].OPEN_PAREN,\n      regex: this.OPEN_PAREN_REGEX\n    });\n  };\n\n  Tokenizer.prototype.getCloseParenToken = function getCloseParenToken(input) {\n    return this.getTokenOnFirstMatch({\n      input: input,\n      type: _tokenTypes2[\"default\"].CLOSE_PAREN,\n      regex: this.CLOSE_PAREN_REGEX\n    });\n  };\n\n  Tokenizer.prototype.getPlaceholderToken = function getPlaceholderToken(input) {\n    return this.getIdentNamedPlaceholderToken(input) || this.getStringNamedPlaceholderToken(input) || this.getIndexedPlaceholderToken(input);\n  };\n\n  Tokenizer.prototype.getIdentNamedPlaceholderToken = function getIdentNamedPlaceholderToken(input) {\n    return this.getPlaceholderTokenWithKey({\n      input: input,\n      regex: this.IDENT_NAMED_PLACEHOLDER_REGEX,\n      parseKey: function parseKey(v) {\n        return v.slice(1);\n      }\n    });\n  };\n\n  Tokenizer.prototype.getStringNamedPlaceholderToken = function getStringNamedPlaceholderToken(input) {\n    var _this2 = this;\n\n    return this.getPlaceholderTokenWithKey({\n      input: input,\n      regex: this.STRING_NAMED_PLACEHOLDER_REGEX,\n      parseKey: function parseKey(v) {\n        return _this2.getEscapedPlaceholderKey({\n          key: v.slice(2, -1),\n          quoteChar: v.slice(-1)\n        });\n      }\n    });\n  };\n\n  Tokenizer.prototype.getIndexedPlaceholderToken = function getIndexedPlaceholderToken(input) {\n    return this.getPlaceholderTokenWithKey({\n      input: input,\n      regex: this.INDEXED_PLACEHOLDER_REGEX,\n      parseKey: function parseKey(v) {\n        return v.slice(1);\n      }\n    });\n  };\n\n  Tokenizer.prototype.getPlaceholderTokenWithKey = function getPlaceholderTokenWithKey(_ref) {\n    var input = _ref.input,\n        regex = _ref.regex,\n        parseKey = _ref.parseKey;\n    var token = this.getTokenOnFirstMatch({\n      input: input,\n      regex: regex,\n      type: _tokenTypes2[\"default\"].PLACEHOLDER\n    });\n\n    if (token) {\n      token.key = parseKey(token.value);\n    }\n\n    return token;\n  };\n\n  Tokenizer.prototype.getEscapedPlaceholderKey = function getEscapedPlaceholderKey(_ref2) {\n    var key = _ref2.key,\n        quoteChar = _ref2.quoteChar;\n    return key.replace(new RegExp((0, _escapeRegExp2[\"default\"])(\"\\\\\") + quoteChar, \"g\"), quoteChar);\n  }; // Decimal, binary, or hex numbers\n\n\n  Tokenizer.prototype.getNumberToken = function getNumberToken(input) {\n    return this.getTokenOnFirstMatch({\n      input: input,\n      type: _tokenTypes2[\"default\"].NUMBER,\n      regex: this.NUMBER_REGEX\n    });\n  }; // Punctuation and symbols\n\n\n  Tokenizer.prototype.getOperatorToken = function getOperatorToken(input) {\n    return this.getTokenOnFirstMatch({\n      input: input,\n      type: _tokenTypes2[\"default\"].OPERATOR,\n      regex: this.OPERATOR_REGEX\n    });\n  };\n\n  Tokenizer.prototype.getReservedWordToken = function getReservedWordToken(input, previousToken) {\n    // A reserved word cannot be preceded by a \".\"\n    // this makes it so in \"mytable.from\", \"from\" is not considered a reserved word\n    if (previousToken && previousToken.value && previousToken.value === \".\") {\n      return;\n    }\n\n    return this.getToplevelReservedToken(input) || this.getNewlineReservedToken(input) || this.getPlainReservedToken(input);\n  };\n\n  Tokenizer.prototype.getToplevelReservedToken = function getToplevelReservedToken(input) {\n    return this.getTokenOnFirstMatch({\n      input: input,\n      type: _tokenTypes2[\"default\"].RESERVED_TOPLEVEL,\n      regex: this.RESERVED_TOPLEVEL_REGEX\n    });\n  };\n\n  Tokenizer.prototype.getNewlineReservedToken = function getNewlineReservedToken(input) {\n    return this.getTokenOnFirstMatch({\n      input: input,\n      type: _tokenTypes2[\"default\"].RESERVED_NEWLINE,\n      regex: this.RESERVED_NEWLINE_REGEX\n    });\n  };\n\n  Tokenizer.prototype.getPlainReservedToken = function getPlainReservedToken(input) {\n    return this.getTokenOnFirstMatch({\n      input: input,\n      type: _tokenTypes2[\"default\"].RESERVED,\n      regex: this.RESERVED_PLAIN_REGEX\n    });\n  };\n\n  Tokenizer.prototype.getWordToken = function getWordToken(input) {\n    return this.getTokenOnFirstMatch({\n      input: input,\n      type: _tokenTypes2[\"default\"].WORD,\n      regex: this.WORD_REGEX\n    });\n  };\n\n  Tokenizer.prototype.getTokenOnFirstMatch = function getTokenOnFirstMatch(_ref3) {\n    var input = _ref3.input,\n        type = _ref3.type,\n        regex = _ref3.regex;\n    var matches = input.match(regex);\n\n    if (matches) {\n      return {\n        type: type,\n        value: matches[1]\n      };\n    }\n  };\n\n  return Tokenizer;\n}();\n\nexports[\"default\"] = Tokenizer;\nmodule.exports = exports[\"default\"];","map":null,"metadata":{},"sourceType":"script"}